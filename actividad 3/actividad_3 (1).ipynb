{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5d7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias para la actividad\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b44ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo no es un archivo zip válido: C:/Users/camil/OneDrive/Documentos/GitHub/ProductoVision/actividad 3/Emojis.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "#En esta sección se cargan las imágenes a color de emojis desde un archivo zip.\n",
    "#Las imágenes se organizan en 5 directorios dentro del zip: Angry, Happy, Poo, Sad y Surprised.\n",
    "path = 'C:/Users/camil/OneDrive/Documentos/GitHub/ProductoVision/actividad 3/Emojis.zip'\n",
    "\n",
    "emojis = []\n",
    "labels = ['Angry', 'Happy', 'Poo', 'Sad', 'Surprised']\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    print(f\"El archivo no existe: {path}\")\n",
    "elif not zipfile.is_zipfile(path):\n",
    "    print(f\"El archivo no es un archivo zip válido: {path}\")\n",
    "else:\n",
    "    with zipfile.ZipFile(path, 'r') as archive:\n",
    "        for label in labels:\n",
    "            # Buscar archivos de imagen en la carpeta correspondiente dentro del zip\n",
    "            for file in archive.namelist():\n",
    "                if file.startswith(label + '/') and file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    with archive.open(file) as img_file:\n",
    "                        file_bytes = np.asarray(bytearray(img_file.read()), dtype=np.uint8)\n",
    "                        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "                        if img is not None:\n",
    "                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                            emojis.append((img, label))\n",
    "\n",
    "    print(\"Número total de imágenes cargadas:\", len(emojis)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645d63fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Muestra una imagen de cada categoría\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    for img, img_label in emojis:\n",
    "        if img_label == label:\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "563fcb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de imágenes preprocesadas: 2530\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento de las imágenes. Las imágenes las vamos a pasar a escala de grises, a un \n",
    "# tamaño de 32x32 píxeles. Desafortunadamente, los trazos no están centrados en la imagen, por lo que\n",
    "# también es necesario encontrar la zona del trazo, y recortarlo para después centrarlo en la imagen.\n",
    "\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Imagen binaria (fondo blanco, trazos negros)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        min_area = 30\n",
    "        all_points = np.vstack([cnt for cnt in contours if cv2.contourArea(cnt) > min_area])\n",
    "        x, y, w, h = cv2.boundingRect(all_points)\n",
    "        roi = binary[y:y+h, x:x+w]  # Usar la imagen binaria\n",
    "        roi_resized = cv2.resize(roi, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "        padded = np.pad(roi_resized, ((2, 2), (2, 2)), mode='constant', constant_values=0)\n",
    "        return padded\n",
    "    else:\n",
    "        return cv2.resize(binary, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "preprocessed_emojis = [(preprocess_image(img), label) for img, label in emojis]\n",
    "print(\"Número total de imágenes preprocesadas:\", len(preprocessed_emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ba3ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Muestra una imagen de cada categoría preprocesada\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    for img, img_label in preprocessed_emojis:\n",
    "        if img_label == label:\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7518a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4624 - loss: 1.1719 - val_accuracy: 0.6453 - val_loss: 1.0018\n",
      "Epoch 2/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4624 - loss: 1.1719 - val_accuracy: 0.6453 - val_loss: 1.0018\n",
      "Epoch 2/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6645 - loss: 0.8374 - val_accuracy: 0.7438 - val_loss: 0.7038\n",
      "Epoch 3/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6645 - loss: 0.8374 - val_accuracy: 0.7438 - val_loss: 0.7038\n",
      "Epoch 3/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.5891 - val_accuracy: 0.8030 - val_loss: 0.6138\n",
      "Epoch 4/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.5891 - val_accuracy: 0.8030 - val_loss: 0.6138\n",
      "Epoch 4/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.4540 - val_accuracy: 0.7882 - val_loss: 0.6013\n",
      "Epoch 5/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.4540 - val_accuracy: 0.7882 - val_loss: 0.6013\n",
      "Epoch 5/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.3658 - val_accuracy: 0.7833 - val_loss: 0.5775\n",
      "Epoch 6/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.3658 - val_accuracy: 0.7833 - val_loss: 0.5775\n",
      "Epoch 6/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8814 - loss: 0.3094 - val_accuracy: 0.7980 - val_loss: 0.5628\n",
      "Epoch 7/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8814 - loss: 0.3094 - val_accuracy: 0.7980 - val_loss: 0.5628\n",
      "Epoch 7/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9127 - loss: 0.2315 - val_accuracy: 0.7833 - val_loss: 0.5977\n",
      "Epoch 8/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9127 - loss: 0.2315 - val_accuracy: 0.7833 - val_loss: 0.5977\n",
      "Epoch 8/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.2124 - val_accuracy: 0.7931 - val_loss: 0.6544\n",
      "Epoch 9/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.2124 - val_accuracy: 0.7931 - val_loss: 0.6544\n",
      "Epoch 9/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.1730 - val_accuracy: 0.8177 - val_loss: 0.6331\n",
      "Epoch 10/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.1730 - val_accuracy: 0.8177 - val_loss: 0.6331\n",
      "Epoch 10/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1552 - val_accuracy: 0.8128 - val_loss: 0.7406\n",
      "Epoch 11/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1552 - val_accuracy: 0.8128 - val_loss: 0.7406\n",
      "Epoch 11/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1412 - val_accuracy: 0.7389 - val_loss: 1.0086\n",
      "Epoch 12/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1412 - val_accuracy: 0.7389 - val_loss: 1.0086\n",
      "Epoch 12/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.1101 - val_accuracy: 0.8325 - val_loss: 0.7733\n",
      "Epoch 13/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.1101 - val_accuracy: 0.8325 - val_loss: 0.7733\n",
      "Epoch 13/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0830 - val_accuracy: 0.7980 - val_loss: 0.8143\n",
      "Epoch 14/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0830 - val_accuracy: 0.7980 - val_loss: 0.8143\n",
      "Epoch 14/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.0911 - val_accuracy: 0.8177 - val_loss: 0.8439\n",
      "Epoch 15/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.0911 - val_accuracy: 0.8177 - val_loss: 0.8439\n",
      "Epoch 15/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.1050 - val_accuracy: 0.8030 - val_loss: 0.8685\n",
      "Epoch 16/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.1050 - val_accuracy: 0.8030 - val_loss: 0.8685\n",
      "Epoch 16/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1168 - val_accuracy: 0.8227 - val_loss: 0.7624\n",
      "Epoch 17/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1168 - val_accuracy: 0.8227 - val_loss: 0.7624\n",
      "Epoch 17/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.0795 - val_accuracy: 0.8177 - val_loss: 0.7384\n",
      "Epoch 18/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.0795 - val_accuracy: 0.8177 - val_loss: 0.7384\n",
      "Epoch 18/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0632 - val_accuracy: 0.8374 - val_loss: 0.8220\n",
      "Epoch 19/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0632 - val_accuracy: 0.8374 - val_loss: 0.8220\n",
      "Epoch 19/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.0817 - val_accuracy: 0.8227 - val_loss: 0.7675\n",
      "Epoch 20/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.0817 - val_accuracy: 0.8227 - val_loss: 0.7675\n",
      "Epoch 20/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0618 - val_accuracy: 0.8079 - val_loss: 0.8715\n",
      "Epoch 21/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0618 - val_accuracy: 0.8079 - val_loss: 0.8715\n",
      "Epoch 21/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0576 - val_accuracy: 0.8325 - val_loss: 0.7289\n",
      "Epoch 22/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0576 - val_accuracy: 0.8325 - val_loss: 0.7289\n",
      "Epoch 22/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0557 - val_accuracy: 0.8473 - val_loss: 0.7836\n",
      "Epoch 23/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0557 - val_accuracy: 0.8473 - val_loss: 0.7836\n",
      "Epoch 23/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0427 - val_accuracy: 0.8079 - val_loss: 0.9055\n",
      "Epoch 24/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0427 - val_accuracy: 0.8079 - val_loss: 0.9055\n",
      "Epoch 24/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0518 - val_accuracy: 0.8473 - val_loss: 0.8418\n",
      "Epoch 25/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0518 - val_accuracy: 0.8473 - val_loss: 0.8418\n",
      "Epoch 25/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0486 - val_accuracy: 0.7882 - val_loss: 0.9427\n",
      "Epoch 26/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0486 - val_accuracy: 0.7882 - val_loss: 0.9427\n",
      "Epoch 26/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9714 - loss: 0.0704 - val_accuracy: 0.8128 - val_loss: 1.0030\n",
      "Epoch 27/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9714 - loss: 0.0704 - val_accuracy: 0.8128 - val_loss: 1.0030\n",
      "Epoch 27/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9775 - loss: 0.0513 - val_accuracy: 0.8030 - val_loss: 1.0702\n",
      "Epoch 28/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9775 - loss: 0.0513 - val_accuracy: 0.8030 - val_loss: 1.0702\n",
      "Epoch 28/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0608 - val_accuracy: 0.8177 - val_loss: 0.8994\n",
      "Epoch 29/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0608 - val_accuracy: 0.8177 - val_loss: 0.8994\n",
      "Epoch 29/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0710 - val_accuracy: 0.8079 - val_loss: 0.8173\n",
      "Epoch 30/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0710 - val_accuracy: 0.8079 - val_loss: 0.8173\n",
      "Epoch 30/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0533 - val_accuracy: 0.8177 - val_loss: 0.7924\n",
      "Epoch 31/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0533 - val_accuracy: 0.8177 - val_loss: 0.7924\n",
      "Epoch 31/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0636 - val_accuracy: 0.8079 - val_loss: 1.0561\n",
      "Epoch 32/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0636 - val_accuracy: 0.8079 - val_loss: 1.0561\n",
      "Epoch 32/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.0979 - val_accuracy: 0.8177 - val_loss: 0.6760\n",
      "Epoch 33/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.0979 - val_accuracy: 0.8177 - val_loss: 0.6760\n",
      "Epoch 33/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0441 - val_accuracy: 0.8276 - val_loss: 0.7793\n",
      "Epoch 34/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0441 - val_accuracy: 0.8276 - val_loss: 0.7793\n",
      "Epoch 34/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0571 - val_accuracy: 0.7980 - val_loss: 1.1515\n",
      "Epoch 35/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0571 - val_accuracy: 0.7980 - val_loss: 1.1515\n",
      "Epoch 35/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0438 - val_accuracy: 0.7783 - val_loss: 1.0338\n",
      "Epoch 36/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0438 - val_accuracy: 0.7783 - val_loss: 1.0338\n",
      "Epoch 36/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.0334 - val_accuracy: 0.8473 - val_loss: 0.8595\n",
      "Epoch 37/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.0334 - val_accuracy: 0.8473 - val_loss: 0.8595\n",
      "Epoch 37/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0423 - val_accuracy: 0.8276 - val_loss: 0.9447\n",
      "Epoch 38/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0423 - val_accuracy: 0.8276 - val_loss: 0.9447\n",
      "Epoch 38/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0458 - val_accuracy: 0.8276 - val_loss: 0.8121\n",
      "Epoch 39/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0458 - val_accuracy: 0.8276 - val_loss: 0.8121\n",
      "Epoch 39/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0365 - val_accuracy: 0.8325 - val_loss: 0.8416\n",
      "Epoch 40/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0365 - val_accuracy: 0.8325 - val_loss: 0.8416\n",
      "Epoch 40/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0358 - val_accuracy: 0.8227 - val_loss: 0.9944\n",
      "Epoch 41/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0358 - val_accuracy: 0.8227 - val_loss: 0.9944\n",
      "Epoch 41/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0367 - val_accuracy: 0.8473 - val_loss: 1.0275\n",
      "Epoch 42/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0367 - val_accuracy: 0.8473 - val_loss: 1.0275\n",
      "Epoch 42/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0462 - val_accuracy: 0.8424 - val_loss: 0.8231\n",
      "Epoch 43/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0462 - val_accuracy: 0.8424 - val_loss: 0.8231\n",
      "Epoch 43/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0459 - val_accuracy: 0.8621 - val_loss: 0.9601\n",
      "Epoch 44/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0459 - val_accuracy: 0.8621 - val_loss: 0.9601\n",
      "Epoch 44/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0495 - val_accuracy: 0.8079 - val_loss: 0.9040\n",
      "Epoch 45/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0495 - val_accuracy: 0.8079 - val_loss: 0.9040\n",
      "Epoch 45/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0375 - val_accuracy: 0.8177 - val_loss: 0.8918\n",
      "Epoch 46/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0375 - val_accuracy: 0.8177 - val_loss: 0.8918\n",
      "Epoch 46/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0644 - val_accuracy: 0.8227 - val_loss: 0.8488\n",
      "Epoch 47/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0644 - val_accuracy: 0.8227 - val_loss: 0.8488\n",
      "Epoch 47/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.0564 - val_accuracy: 0.7734 - val_loss: 1.2320\n",
      "Epoch 48/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.0564 - val_accuracy: 0.7734 - val_loss: 1.2320\n",
      "Epoch 48/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0374 - val_accuracy: 0.8374 - val_loss: 1.0041\n",
      "Epoch 49/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0374 - val_accuracy: 0.8374 - val_loss: 1.0041\n",
      "Epoch 49/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0389 - val_accuracy: 0.8325 - val_loss: 1.1008\n",
      "Epoch 50/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.0389 - val_accuracy: 0.8325 - val_loss: 1.1008\n",
      "Epoch 50/50\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0550 - val_accuracy: 0.8227 - val_loss: 0.9510\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0550 - val_accuracy: 0.8227 - val_loss: 0.9510\n",
      "\n",
      "Precisión en test: 0.838\n",
      "\n",
      "Precisión en test: 0.838\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.79      0.53      0.64       101\n",
      "       Happy       0.84      0.93      0.88       102\n",
      "         Poo       1.00      1.00      1.00       101\n",
      "         Sad       0.67      0.79      0.73       101\n",
      "   Surprised       0.90      0.93      0.91       101\n",
      "\n",
      "    accuracy                           0.84       506\n",
      "   macro avg       0.84      0.84      0.83       506\n",
      "weighted avg       0.84      0.84      0.83       506\n",
      "\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.79      0.53      0.64       101\n",
      "       Happy       0.84      0.93      0.88       102\n",
      "         Poo       1.00      1.00      1.00       101\n",
      "         Sad       0.67      0.79      0.73       101\n",
      "   Surprised       0.90      0.93      0.91       101\n",
      "\n",
      "    accuracy                           0.84       506\n",
      "   macro avg       0.84      0.84      0.83       506\n",
      "weighted avg       0.84      0.84      0.83       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ajuste y evaluación de un modelo MLP mejorado con normalización y Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preparar datos\n",
    "X = np.array([img for img, label in preprocessed_emojis])\n",
    "X = X.reshape((X.shape[0], -1))  # Aplanar imágenes\n",
    "X = X.astype('float32') / 255.0  # Normalizar a [0,1]\n",
    "label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "y = np.array([label_to_idx[label] for _, label in preprocessed_emojis])\n",
    "y_cat = to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "# Separar en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Definir modelo MLP mejorado\n",
    "mlp = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(labels), activation='softmax')\n",
    "])\n",
    "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar\n",
    "history = mlp.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluar\n",
    "loss, acc = mlp.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nPrecisión en test: {acc:.3f}\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "y_pred = np.argmax(mlp.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9b2ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5739 - loss: 1.0386 - val_accuracy: 0.7931 - val_loss: 0.5780\n",
      "Epoch 2/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5739 - loss: 1.0386 - val_accuracy: 0.7931 - val_loss: 0.5780\n",
      "Epoch 2/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.5409 - val_accuracy: 0.8473 - val_loss: 0.4291\n",
      "Epoch 3/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.5409 - val_accuracy: 0.8473 - val_loss: 0.4291\n",
      "Epoch 3/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8347 - loss: 0.4046 - val_accuracy: 0.8571 - val_loss: 0.3475\n",
      "Epoch 4/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8347 - loss: 0.4046 - val_accuracy: 0.8571 - val_loss: 0.3475\n",
      "Epoch 4/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8677 - loss: 0.3228 - val_accuracy: 0.9015 - val_loss: 0.2524\n",
      "Epoch 5/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8677 - loss: 0.3228 - val_accuracy: 0.9015 - val_loss: 0.2524\n",
      "Epoch 5/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8896 - loss: 0.2805 - val_accuracy: 0.9113 - val_loss: 0.2767\n",
      "Epoch 6/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8896 - loss: 0.2805 - val_accuracy: 0.9113 - val_loss: 0.2767\n",
      "Epoch 6/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9220 - loss: 0.2113 - val_accuracy: 0.9163 - val_loss: 0.2013\n",
      "Epoch 7/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9220 - loss: 0.2113 - val_accuracy: 0.9163 - val_loss: 0.2013\n",
      "Epoch 7/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9237 - loss: 0.1957 - val_accuracy: 0.9310 - val_loss: 0.1958\n",
      "Epoch 8/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9237 - loss: 0.1957 - val_accuracy: 0.9310 - val_loss: 0.1958\n",
      "Epoch 8/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.1689 - val_accuracy: 0.9261 - val_loss: 0.1742\n",
      "Epoch 9/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.1689 - val_accuracy: 0.9261 - val_loss: 0.1742\n",
      "Epoch 9/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.1528 - val_accuracy: 0.9507 - val_loss: 0.1339\n",
      "Epoch 10/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.1528 - val_accuracy: 0.9507 - val_loss: 0.1339\n",
      "Epoch 10/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.1327 - val_accuracy: 0.9458 - val_loss: 0.1654\n",
      "Epoch 11/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.1327 - val_accuracy: 0.9458 - val_loss: 0.1654\n",
      "Epoch 11/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9605 - loss: 0.1023 - val_accuracy: 0.9360 - val_loss: 0.1802\n",
      "Epoch 12/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9605 - loss: 0.1023 - val_accuracy: 0.9360 - val_loss: 0.1802\n",
      "Epoch 12/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.1019 - val_accuracy: 0.9360 - val_loss: 0.1470\n",
      "Epoch 13/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.1019 - val_accuracy: 0.9360 - val_loss: 0.1470\n",
      "Epoch 13/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.0938 - val_accuracy: 0.9409 - val_loss: 0.1525\n",
      "Epoch 14/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.0938 - val_accuracy: 0.9409 - val_loss: 0.1525\n",
      "Epoch 14/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9638 - loss: 0.0884 - val_accuracy: 0.9458 - val_loss: 0.1307\n",
      "Epoch 15/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9638 - loss: 0.0884 - val_accuracy: 0.9458 - val_loss: 0.1307\n",
      "Epoch 15/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9588 - loss: 0.0954 - val_accuracy: 0.9310 - val_loss: 0.1422\n",
      "Epoch 16/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9588 - loss: 0.0954 - val_accuracy: 0.9310 - val_loss: 0.1422\n",
      "Epoch 16/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.0916 - val_accuracy: 0.9310 - val_loss: 0.1612\n",
      "Epoch 17/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.0916 - val_accuracy: 0.9310 - val_loss: 0.1612\n",
      "Epoch 17/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9736 - loss: 0.0691 - val_accuracy: 0.9458 - val_loss: 0.1559\n",
      "Epoch 18/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9736 - loss: 0.0691 - val_accuracy: 0.9458 - val_loss: 0.1559\n",
      "Epoch 18/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.0733 - val_accuracy: 0.9409 - val_loss: 0.1493\n",
      "Epoch 19/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.0733 - val_accuracy: 0.9409 - val_loss: 0.1493\n",
      "Epoch 19/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0635 - val_accuracy: 0.9360 - val_loss: 0.1667\n",
      "Epoch 20/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0635 - val_accuracy: 0.9360 - val_loss: 0.1667\n",
      "Epoch 20/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0549 - val_accuracy: 0.9557 - val_loss: 0.1634\n",
      "Epoch 21/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0549 - val_accuracy: 0.9557 - val_loss: 0.1634\n",
      "Epoch 21/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0714 - val_accuracy: 0.9310 - val_loss: 0.1667\n",
      "Epoch 22/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0714 - val_accuracy: 0.9310 - val_loss: 0.1667\n",
      "Epoch 22/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0543 - val_accuracy: 0.9360 - val_loss: 0.1577\n",
      "Epoch 23/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0543 - val_accuracy: 0.9360 - val_loss: 0.1577\n",
      "Epoch 23/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9747 - loss: 0.0605 - val_accuracy: 0.9507 - val_loss: 0.1252\n",
      "Epoch 24/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9747 - loss: 0.0605 - val_accuracy: 0.9507 - val_loss: 0.1252\n",
      "Epoch 24/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.0716 - val_accuracy: 0.9310 - val_loss: 0.1540\n",
      "Epoch 25/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.0716 - val_accuracy: 0.9310 - val_loss: 0.1540\n",
      "Epoch 25/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0547 - val_accuracy: 0.9409 - val_loss: 0.1708\n",
      "Epoch 26/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0547 - val_accuracy: 0.9409 - val_loss: 0.1708\n",
      "Epoch 26/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0525 - val_accuracy: 0.9409 - val_loss: 0.1714\n",
      "Epoch 27/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0525 - val_accuracy: 0.9409 - val_loss: 0.1714\n",
      "Epoch 27/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0468 - val_accuracy: 0.9507 - val_loss: 0.1384\n",
      "Epoch 28/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0468 - val_accuracy: 0.9507 - val_loss: 0.1384\n",
      "Epoch 28/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0424 - val_accuracy: 0.9458 - val_loss: 0.1833\n",
      "Epoch 29/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0424 - val_accuracy: 0.9458 - val_loss: 0.1833\n",
      "Epoch 29/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0529 - val_accuracy: 0.9360 - val_loss: 0.1574\n",
      "Epoch 30/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0529 - val_accuracy: 0.9360 - val_loss: 0.1574\n",
      "Epoch 30/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0451 - val_accuracy: 0.9310 - val_loss: 0.1570\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0451 - val_accuracy: 0.9310 - val_loss: 0.1570\n",
      "\n",
      "Precisión en test (CNN): 0.960\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
      "Precisión en test (CNN): 0.960\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "Reporte de clasificación (CNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.93      0.90      0.91       101\n",
      "       Happy       0.98      1.00      0.99       102\n",
      "         Poo       1.00      1.00      1.00       101\n",
      "         Sad       0.89      0.91      0.90       101\n",
      "   Surprised       1.00      0.99      1.00       101\n",
      "\n",
      "    accuracy                           0.96       506\n",
      "   macro avg       0.96      0.96      0.96       506\n",
      "weighted avg       0.96      0.96      0.96       506\n",
      "\n",
      "\n",
      "Reporte de clasificación (CNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.93      0.90      0.91       101\n",
      "       Happy       0.98      1.00      0.99       102\n",
      "         Poo       1.00      1.00      1.00       101\n",
      "         Sad       0.89      0.91      0.90       101\n",
      "   Surprised       1.00      0.99      1.00       101\n",
      "\n",
      "    accuracy                           0.96       506\n",
      "   macro avg       0.96      0.96      0.96       506\n",
      "weighted avg       0.96      0.96      0.96       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ajuste y evaluación de una CNN para las imágenes binarias\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preparar datos para CNN\n",
    "X = np.array([img for img, label in preprocessed_emojis])\n",
    "X = X.astype('float32') / 255.0  # Normalizar\n",
    "X = X[..., np.newaxis]  # Añadir canal para CNN (shape: N, 36, 36, 1)\n",
    "label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "y = np.array([label_to_idx[label] for _, label in preprocessed_emojis])\n",
    "y_cat = to_categorical(y, num_classes=len(labels))\n",
    "\n",
    "# Separar en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Definir modelo CNN\n",
    "cnn = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(X.shape[1], X.shape[2], 1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(labels), activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar\n",
    "history_cnn = cnn.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluar\n",
    "loss, acc = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nPrecisión en test (CNN): {acc:.3f}\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "y_pred = np.argmax(cnn.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(\"\\nReporte de clasificación (CNN):\\n\", classification_report(y_true, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
